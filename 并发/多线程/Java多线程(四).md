# Java多线程(四)

## 一、并发编程挑战

### 1、上下文切换

#### 1)、时间片

即使是单核处理器也支持多线程执行代码，CPU通过给每个线程分配**CPU时间片**来实现这个机制。

时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停地切换线程执行，让我们感觉多个线程是同时执行的，时间片一般是几十毫秒（ms）。

#### 2)、并行一定更快吗？

相同的程序，并行版本不一定比串行快。

因为CPU在由一个线程切换到另一个线程时，需要保留该线程当下的执行状态（执行到了哪一行，有哪些变量和变量值），在下次继续执行该线程时恢复到原来的状态，这个保存-恢复会消耗一定得到时间。

#### 3)、如何避免频繁的上下文切换?

* 1)、降低锁粒度: 如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据，这在`ConcurrentHashMap`中有所体现。
* 2)、CAS算法(CAS无所操作)。**Java的Atomic包使用CAS算法来更新数据，而不需要加锁**。不同于`synchronized`在获得释放锁的过程中会引起线程的切换。
* 3)、使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这
  样会造成大量线程都处于等待状态，尽量使用线程池技术。

协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换

### 2、死锁

如何避免死锁?

1. **避免一个线程同时获取多个锁**；
2. 避免一个线程同时占用多个资源，尽量保证每个锁只占用一个资源；
3. 尝试使用**定时锁**，使用`lock.tryLock(timeout)`来替代使用内部锁机制，一定时间获取不到就返回；
4. 对于数据库锁，**加锁和解锁必须在一个数据库连接里**，否则会出现解锁失败的情况；

## 二、并发机制底层实现原理

### 1、本地内存和线程安全问题

相关:

* 1)、缓存行: CPU不会直接和内存交互，而是通过总线将数据读到自己的缓存行中。
* 2)、写缓冲区: CPU不会直接和内存交互，会将要读取的数据先写入到自己的写缓冲区，随后才会刷新到内存。
* 3)、本地内存: 这是虚拟出来的概念，实际并不存在，包括了**缓冲行，写缓冲区**等概念。
  * 实际中都是由很多CPU来执行并发程序，不同处理器同时执行不同的线程（每个线程都有一个仅对执行自己的处理器可见的本地内存)。
  * 所以就会出现主内存中`i = 1`，线程A读取到自己的本地内存i++，于此同时线程B也读取到主内存`i= 1`到自己的本地内存执行i++，待两个线程的本地内存刷新到主内存时`i = 2`。于是引发了线程安全问题。

线程安全问题总结:

* 线程都是在自己的本地内存中操作共享变量的，仅对执行自己的处理器可见而对其他处理器不可见。
* 而它们在自己的本地内存对共享变量的更新何时会刷新到主内存、会按照什么顺序刷新到主内存是不可预见的。

使用volatile关键字可以保证共享变量之间的可见性。

volatile做的两件事:

* 1)、锁定缓存行；
* 2)、刷新内存，保证数据一致性；

![1555499561112](assets/1555499561112.png)

一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：

1. 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。
2. **禁止进行指令重排序**。

### 2、volatile实现原理

加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，**加入volatile关键字时，会多出一个lock前缀指令**

lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：

1. 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
2. 它会强制将对缓存的修改操作立即写入主存；
3. 如果是写操作，它会导致其他CPU中对应的缓存行无效。


# 并发机制底层实现原理

## 一、本地内存和线程安全问题

### 1、缓存行

CPU不会直接和内存(主存)交互，而是通过总线将数据读到自己的缓存行中。

### 2、写缓冲区

CPU不会直接和内存(主存)交互，会将要读取的数据先写入到自己的写缓冲区，随后才会刷新到内存。

### 3、线程安全问题

* 实际中都是由很多CPU来执行并发程序，不同处理器同时执行不同的线程（每个线程都有一个仅对执行自己的处理器可见的本地内存)。
* 所以就会出现主内存中`i = 1`，线程A读取到自己的本地内存`i++`，于此同时线程B也读取到主内存`i= 1`到自己的本地内存执行i++，待两个线程的本地内存刷新到主内存时`i = 2`。于是引发了线程安全问题。

![1556199651448](assets/1556199651448.png)

线程安全问题总结:

* **线程都是在自己的本地内存中操作共享变量的，仅对执行自己的处理器可见而对其他处理器不可见**。
* 而它们在自己的本地内存对共享变量的更新何时会刷新到主内存、会按照什么顺序刷新到主内存是不可预见的。

## 二、volatile实现原理

### 1、volatile语义

使用volatile关键字可以**保证共享变量之间的可见性**，被`volatile`修饰的变量在线程之间就是可见的，能保证变量被一致性的更新。

volatile做的两件事:

- 1、锁定缓存行；
  - 在某个处理器将共享数据写入自己的缓冲区 (对应线程对本地内存中的共享记量做修改) 时，会使用缓存锁定其他也读取了该共享记量的缓存行，使其他处理器不能访问该共享专量。 
  - 早期使用的是总线锁定，即一经锁定，其他处理器就不能访问所有共享记量，但是这会影响处理器读写其他共享变量，影响效率。
- 2、刷新内存，保证数据一致性；
  - 该处理器将自己写缓冲区中的所有数据刷新到主内存 (包括非volatile变量) 。
  - 由**缓存一致性协议**来保证其他CPU重新读数据 (其他处理器会通过总线嗅探其他处理器写组冲区中的更改，一经发现就会将自己的缓存行置为无效状态(看自己的是不是过期了)，下次访问数据时需要到主内存中重新读)

一旦一个共享变量（类的成员变量、类的静态成员变量）被`volatile`修饰之后，那么就具备了两层语义：

* 1、保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。
* 2、**禁止进行指令重排序**。

> 由于缓存行为`32`字节宽或者`64`字节宽，因此避免缓存锁定多个共享资源，可以采用**字节填充**的方式来提高对象并发性能。

### 2、Lock前缀指令

加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，**加入volatile关键字时，会多出一个lock前缀指令**

lock前缀指令实际上相当于一个**内存屏障**（也成内存栅栏），内存屏障会提供3个功能：

* 1、它确保指令重排序时**不会把其后面的指令排到内存屏障之前的位置**，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
* 2、**它会强制将对缓存的修改操作立即写入主存**；
* 3、如果是写操作，它会导致其他CPU(处理器)中对应的缓存行无效。

在JVM底层volatile是采用“内存屏障”来实现的。

第一层语义就不做介绍了，下面重点介绍指令重排序。

在执行程序时为了提高性能，编译器和处理器通常会对指令做重排序：

* 1、编译器重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序；
* 2、处理器重排序。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序；

指令重排序对单线程没有什么影响，他不会影响程序的运行结果，但是会影响多线程的正确性。

既然指令重排序会影响到多线程执行的正确性，那么我们就需要禁止重排序。

那么JVM是如何禁止重排序的呢？这个问题稍后回答，我们先看另一个原则`happens-before`，happen-before原则保证了程序的“有序性”，**它规定如果两个操作的执行顺序无法从`happens-before`原则中推导出来，那么他们就不能保证有序性，可以随意进行重排序**。其定义如下：

* 1、同一个线程中的，前面的操作 happen-before 后续的操作。（即单线程内按代码顺序执行。但是，在不影响在单线程环境执行结果的前提下，编译器和处理器可以进行重排序，这是合法的。换句话说，这一是规则无法保证编译重排和指令重排）。
* 2、监视器上的解锁操作 happen-before 其后续的加锁操作。（Synchronized 规则）
* 3、**对volatile变量的写操作 happen-before 后续的读操作**。（volatile 规则）
* 4、线程的start() 方法 happen-before 该线程所有的后续操作。（线程启动规则）
* 5、线程所有的操作 happen-before 其他线程在该线程上调用 join 返回成功后的操作。
* 6、如果 a happen-before b，b happen-before c，则a happen-before c（传递性）。

我们着重看第三点volatile规则：对volatile变量的写操作 happen-before 后续的读操作。为了实现volatile内存语义，JMM会重排序。

## 三、sychronized实现原理

利用synchronized实现同步的基础，Java中的每一个对象都可以作为锁，有以下3种形式

- 对于普通同步方法，锁是当前实例对象
- 对于静态同步方法，锁是当前类的Class对象
- 对于同步方法块，锁住的是synchonized括号里配置的对象

Java 虚拟机中的同步(Synchronization)是基于进入和退出**Monitor对象**实现， **无论是显式同步(有明确的 monitorenter 和 monitorexit 指令**，即同步代码块)还是隐式同步都是如此。

在 Java 语言中，同步用的最多的地方可能是被 synchronized 修饰的同步方法。**同步方法并不是由monitorenter 和 monitorexit 指令来实现同步的，而是由方法调用指令读取运行时常量池中方法的 ACC_SYNCHRONIZED 标志来隐式实现的**。

```java
1    public void add(Object obj){
2        synchronized (obj){
3            //do something
4        }
5    }

反编译后：
 1public class com.zxin.thread.SynchronizedDemo {
 2  public com.wuzy.thread.SynchronizedDemo();
 3    Code:
 4       0: aload_0
 5       1: invokespecial #1                  // Method java/lang/Object."<init>":()V
 6       4: return
 7
 8  public void add(java.lang.Object);
 9    Code:
10       0: aload_1
11       1: dup
12       2: astore_2
13       3: monitorenter //注意此处，进入同步方法
14       4: aload_2
15       5: monitorexit //注意此处，退出同步方法
16       6: goto          14
17       9: astore_3
18      10: aload_2
19      11: monitorexit //注意此处，退出同步方法
20      12: aload_3
21      13: athrow
22      14: return
23    Exception table:
24       from    to  target type
25           4     6     9   any
26           9    12     9   any
27}
```

我们看下第13行~15行代码**，发现同步代码块是使用monitorenter和monitorexit指令来进行代码同步的,注意看第19行代码，为什么会多出一个monitorexit指令，主要是JVM为了防止代码出现异常**，也能正确退出同步方法。

同步方法并不是用monitorenter和monitorexit指令来进行同步的，实际上同步方法会被翻译成普通的方法调用和返回指令如:invokevirtual、areturn指令，在VM字节码层面并没有任何特别的指令来实现被synchronized修饰的方法，而是**在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置设为1**，表示该方法是同步方法并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示做为锁对象。

## 四、原子操作实现原理
